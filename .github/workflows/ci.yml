name: CI/CD Pipeline

on:
  push:
    branches: [ main, develop ]
  pull_request:
    branches: [ main, develop ]
  workflow_dispatch:

env:
  PYTHON_VERSION: '3.11'

jobs:
  # ç»Ÿä¸€æµ‹è¯•é˜¶æ®µ - ç®€åŒ–ç‰ˆæœ¬
  test:
    name: ğŸ§ª Run All Tests
    runs-on: ubuntu-latest
    timeout-minutes: 30
    
    steps:
    - name: Checkout code
      uses: actions/checkout@v4
      
    - name: Set up Python
      uses: actions/setup-python@v4
      with:
        python-version: ${{ env.PYTHON_VERSION }}
        
    - name: Install dependencies
      run: |
        python -m pip install --upgrade pip
        pip install -r requirements.txt
        
    - name: Create test reports directory
      run: |
        mkdir -p test-reports
        
    - name: Run unit tests
      run: |
        python -m pytest v2/tests/unit/ -v \
          --junitxml=test-reports/unit-junit.xml \
          --cov=v2 \
          --cov-report=xml:test-reports/unit-coverage.xml \
          --cov-report=html:test-reports/unit-coverage-html
      continue-on-error: false
        
    - name: Run integration tests
      run: |
        python -m pytest v2/tests/integration/ -v \
          --junitxml=test-reports/integration-junit.xml \
          --cov=v2 --cov-append \
          --cov-report=xml:test-reports/integration-coverage.xml \
          --cov-report=html:test-reports/integration-coverage-html
      continue-on-error: false
        
    - name: Run meta tests
      run: |
        python -m pytest v2/tests/meta/ -v \
          --junitxml=test-reports/meta-junit.xml \
          --cov=v2 --cov-append \
          --cov-report=xml:test-reports/meta-coverage.xml \
          --cov-report=html:test-reports/meta-coverage-html
      continue-on-error: false
      
    - name: Generate test summary
      if: always()
      run: |
        cat > test-summary.py << 'EOF'
        #!/usr/bin/env python3
        import xml.etree.ElementTree as ET
        import glob
        import os
        
        def parse_junit_results():
            results = {
                'total': 0,
                'passed': 0,
                'failed': 0,
                'errors': 0,
                'skipped': 0,
                'suites': []
            }
            
            junit_files = glob.glob('test-reports/*-junit.xml')
            print(f"Found {len(junit_files)} JUnit files:")
            
            for junit_file in junit_files:
                print(f"  Processing: {junit_file}")
                try:
                    tree = ET.parse(junit_file)
                    root = tree.getroot()
                    
                    tests = int(root.get('tests', 0))
                    failures = int(root.get('failures', 0))
                    errors = int(root.get('errors', 0))
                    skipped = int(root.get('skipped', 0))
                    passed = tests - failures - errors - skipped
                    
                    suite_name = os.path.basename(junit_file).replace('-junit.xml', '')
                    
                    results['total'] += tests
                    results['passed'] += passed
                    results['failed'] += failures
                    results['errors'] += errors
                    results['skipped'] += skipped
                    
                    results['suites'].append({
                        'name': suite_name,
                        'tests': tests,
                        'passed': passed,
                        'failed': failures,
                        'errors': errors,
                        'skipped': skipped
                    })
                    
                    print(f"    Tests: {tests}, Passed: {passed}, Failed: {failures}, Errors: {errors}")
                    
                except Exception as e:
                    print(f"Error parsing {junit_file}: {e}")
            
            return results
        
        def generate_summary(results):
            print("\n" + "="*60)
            print("ğŸ¯ CIæµ‹è¯•ç»“æœæ±‡æ€»")
            print("="*60)
            print(f"æ€»æµ‹è¯•æ•°: {results['total']}")
            print(f"âœ… é€šè¿‡: {results['passed']}")
            print(f"âŒ å¤±è´¥: {results['failed']}")
            print(f"âš ï¸ é”™è¯¯: {results['errors']}")
            print(f"â­ï¸ è·³è¿‡: {results['skipped']}")
            
            if results['total'] > 0:
                pass_rate = (results['passed'] / results['total']) * 100
                print(f"ğŸ“Š é€šè¿‡ç‡: {pass_rate:.1f}%")
            
            print("\nğŸ“‹ æµ‹è¯•å¥—ä»¶è¯¦æƒ…:")
            for suite in results['suites']:
                status = "âœ…" if suite['failed'] == 0 and suite['errors'] == 0 else "âŒ"
                print(f"  {status} {suite['name']}: {suite['tests']} æµ‹è¯•")
            
            # åˆ¤æ–­æ€»ä½“ç»“æœ
            all_passed = results['failed'] == 0 and results['errors'] == 0
            overall_status = "âœ… é€šè¿‡" if all_passed else "âŒ å¤±è´¥"
            
            print(f"\nğŸ† æ€»ä½“ç»“æœ: {overall_status}")
            
            # è®¾ç½®GitHub Actionsè¾“å‡º
            if 'GITHUB_OUTPUT' in os.environ:
                with open(os.environ['GITHUB_OUTPUT'], 'a') as f:
                    f.write(f"tests_passed={str(all_passed).lower()}\n")
                    f.write(f"total_tests={results['total']}\n")
                    f.write(f"failed_tests={results['failed']}\n")
                    f.write(f"error_tests={results['errors']}\n")
            
            return all_passed
        
        def main():
            results = parse_junit_results()
            success = generate_summary(results)
            
            if not success:
                print("\nâŒ æµ‹è¯•å¤±è´¥ï¼ŒCIå°†é€€å‡ºå¹¶è¿”å›é”™è¯¯ç ")
                exit(1)
            else:
                print("\nâœ… æ‰€æœ‰æµ‹è¯•é€šè¿‡ï¼ŒCIæˆåŠŸå®Œæˆ")
        
        if __name__ == '__main__':
            main()
        EOF
        
        python test-summary.py
      
    - name: Upload test results
      if: always()
      uses: actions/upload-artifact@v3
      with:
        name: test-results
        path: test-reports/
        retention-days: 30
        
    - name: Comment PR with results
      if: github.event_name == 'pull_request' && always()
      uses: actions/github-script@v6
      with:
        script: |
          const fs = require('fs');
          const { execSync } = require('child_process');
          
          try {
            // è¿è¡Œæµ‹è¯•æ±‡æ€»è„šæœ¬è·å–ç»“æœ
            const output = execSync('python test-summary.py', { encoding: 'utf8' });
            
            github.rest.issues.createComment({
              issue_number: context.issue.number,
              owner: context.repo.owner,
              repo: context.repo.repo,
              body: `## ğŸ¯ CIæµ‹è¯•ç»“æœ\n\n\`\`\`\n${output}\n\`\`\``
            });
          } catch (error) {
            console.log('Failed to generate test summary for PR comment:', error);
          }